{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52227e0-46cc-4455-a453-942c9791b460",
   "metadata": {},
   "source": [
    "## Nuova versione di AccoppiamentoDati.ipynb -> in questa versione molte funzioni sono importate dal file utilstre.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0af6d96-a210-47a5-bed0-462bf8ffb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "import sys, os, pickle, numpy as np\n",
    "# Verifica che la cartella lib esista\n",
    "lib_path = 'lib'  # Percorso della cartella lib/\n",
    "assert os.path.isdir(lib_path), f\"Percorso lib non trovato: {lib_path}\"\n",
    "\n",
    "# Aggiungi lib/ al path se non è già presente\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.append(lib_path)\n",
    "\n",
    "\n",
    "from lib.utilstre import (\n",
    "    match_patient_txt_files,\n",
    "    make_npz_from_txt_files,\n",
    "    load_data_by_patient,\n",
    "    save_split_npz,\n",
    ")\n",
    "\n",
    "# Cartelle con i .txt per i due task (A e B)\n",
    "\n",
    "FOLDER_A= '../../HCP/RestingStateLR_dataset/'\n",
    "FOLDER_B = '../../HCP/LanguageTaskLR_dataset/' \n",
    "#FOLDER_B = '../../HCP/MemoryTaskLR_dataset/'\n",
    " \n",
    "\n",
    "# Dove salvare i .npz intermedi (uno per task) e lo split finale\n",
    "NPZ_A = \"TaskA.npz\"      # es. \"RestingState.npz\"\n",
    "NPZ_B = \"TaskB.npz\"      # es. \"WorkingMemory.npz\"\n",
    "OUT_SPLIT = \"split_caseX_A_vs_B.npz\"  # verrà aggiornato più sotto\n",
    "\n",
    "# Colonne da scartare all'inizio (le 6 di riferimento paziente)\n",
    "KEEP_FIRST_K = 6\n",
    "\n",
    "# come gestire lunghezze T diverse intra-task e tra task: \"min\" oppure \"pad\"\n",
    "ALIGN_T_INTRA  = \"min\"   # nella costruzione dei singoli .npz\n",
    "ALIGN_T_ACROSS = \"min\"   # quando carichiamo A e B insieme\n",
    "\n",
    "# split e seed\n",
    "CASE = 1            # <-- scegli 1, 2 o 3\n",
    "# case=1: Train su A (subset pazienti), Val/Test su B sugli *stessi pazienti*.\n",
    "# case=2: Train su A (subset pazienti), Val/Test su A su *pazienti diversi*.\n",
    "# case=3: Train su A (subset pazienti), Val/Test su B su *pazienti diversi*.\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE  = 0.2\n",
    "SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a89a56-00a7-428f-a687-7761d61fd1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pazienti in comune: 1042\n",
      "Esempio ID: ['100206', '100307', '100408', '100610', '101006']\n",
      "A -> TaskA.npz shape: (1042, 922, 6)\n",
      "B -> TaskB.npz shape: (1042, 288, 6)\n"
     ]
    }
   ],
   "source": [
    "filesA, filesB, ids = match_patient_txt_files(FOLDER_A, FOLDER_B)\n",
    "print(f\"Pazienti in comune: {len(ids)}\")\n",
    "print(\"Esempio ID:\", ids[:5])\n",
    "\n",
    "a_npz_path, a_shape, a_ids = make_npz_from_txt_files(\n",
    "    filesA, NPZ_A, keep_first_k=KEEP_FIRST_K, align_T=ALIGN_T_INTRA\n",
    ")\n",
    "b_npz_path, b_shape, b_ids = make_npz_from_txt_files(\n",
    "    filesB, NPZ_B, keep_first_k=KEEP_FIRST_K, align_T=ALIGN_T_INTRA\n",
    ")\n",
    "\n",
    "\n",
    "print(\"A ->\", a_npz_path, \"shape:\", a_shape)\n",
    "print(\"B ->\", b_npz_path, \"shape:\", b_shape)\n",
    "assert len(a_ids) == len(b_ids) == len(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b8d039-dd20-40b3-a27c-58ae9740a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: (833, 288, 6) VAL: (416, 288, 6) TEST: (417, 288, 6)\n",
      "N train_ids: 833 N test_ids: 833\n"
     ]
    }
   ],
   "source": [
    "# Nota: enforce_same_order True perché i due .npz ora hanno lo stesso ordine di patient_ids\n",
    "scalers, Xtr, Xval, Xte, train_ids, test_ids = load_data_by_patient(\n",
    "    dataA_path=NPZ_A,\n",
    "    dataB_path=NPZ_B,\n",
    "    case=CASE,\n",
    "    test_size=TEST_SIZE,\n",
    "    val_size=VAL_SIZE,\n",
    "    random_state=SEED,\n",
    "    enforce_same_order=True,\n",
    "    align_T_mode=ALIGN_T_ACROSS,\n",
    ")\n",
    "\n",
    "print(\"TRAIN:\", Xtr.shape, \"VAL:\", Xval.shape, \"TEST:\", Xte.shape)\n",
    "print(\"N train_ids:\", len(train_ids), \"N test_ids:\", len(test_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168742a6-e924-438d-8ec3-2435aeeceb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: split_case1_A_TaskA_B_TaskB.npz\n"
     ]
    }
   ],
   "source": [
    "# Costruisci un nome file significativo\n",
    "OUT_SPLIT = f\"split_case{CASE}_A_{os.path.splitext(NPZ_A)[0]}_B_{os.path.splitext(NPZ_B)[0]}.npz\"\n",
    "\n",
    "from utilstre import save_split_npz\n",
    "path_out = save_split_npz(\n",
    "    out_path=OUT_SPLIT,\n",
    "    X_train=Xtr, X_val=Xval, X_test=Xte,\n",
    "    train_ids=train_ids, test_ids=test_ids,\n",
    "    scalers=scalers,   # opzionale ma utile\n",
    ")\n",
    "print(\"Salvato:\", path_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a8f17-fa2f-4e49-87d0-4457c5737974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_light",
   "language": "python",
   "name": "pytorch_light"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
